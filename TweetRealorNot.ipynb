{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":300,"outputs":[{"output_type":"stream","text":"/kaggle/input/sample_submission.csv\n/kaggle/input/test.csv\n/kaggle/input/train.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":301,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/train.csv')","execution_count":302,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":303,"outputs":[{"output_type":"execute_result","execution_count":303,"data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":304,"outputs":[{"output_type":"execute_result","execution_count":304,"data":{"text/plain":"id             0\nkeyword       61\nlocation    2533\ntext           0\ntarget         0\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['id','keyword','location'],axis=1)","execution_count":305,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":306,"outputs":[{"output_type":"execute_result","execution_count":306,"data":{"text/plain":"                                                   text  target\n0     Our Deeds are the Reason of this #earthquake M...       1\n1                Forest fire near La Ronge Sask. Canada       1\n2     All residents asked to 'shelter in place' are ...       1\n3     13,000 people receive #wildfires evacuation or...       1\n4     Just got sent this photo from Ruby #Alaska as ...       1\n...                                                 ...     ...\n7608  Two giant cranes holding a bridge collapse int...       1\n7609  @aria_ahrary @TheTawniest The out of control w...       1\n7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1\n7611  Police investigating after an e-bike collided ...       1\n7612  The Latest: More Homes Razed by Northern Calif...       1\n\n[7613 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7608</th>\n      <td>Two giant cranes holding a bridge collapse int...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>Police investigating after an e-bike collided ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>The Latest: More Homes Razed by Northern Calif...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7613 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\ndef rem_punct(text):\n    for punctuation in string.punctuation:\n        text = text.replace(punctuation , '')\n    return text\ndf['text'] = df['text'].apply(rem_punct)\n        ","execution_count":307,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords","execution_count":308,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk.download('stopwords')","execution_count":309,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","name":"stdout"},{"output_type":"execute_result","execution_count":309,"data":{"text/plain":"True"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem.porter import PorterStemmer","execution_count":310,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stemmer = PorterStemmer()","execution_count":311,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop = set(stopwords.words('english'))\ndef stem_text(text):\n    f_text = []\n    for i in text.split():    # split the sentenses into List With commas\n        if i.strip().lower not in stop:        #strip means you wanna strip/delete that word from list of split or delete whitespaces if no agument is passed\n            word = stemmer.stem(i.strip())\n            f_text.append(word)\n    return \" \".join(f_text)\n\ndf['text'] = df['text'].apply(stem_text)\n    \n            \n    ","execution_count":312,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import seaborn as sns\n#import matplotlib.pyplot as plt\n#from wordcloud import WordCloud , STOPWORDS\n#plt.figure(figsize = (20,20))\n#wc = WordCloud(max_words=4000 , width=1200 , height=6500, stopwords = STOPWORDS ).generate(\" \".join(df.text))\n#plt.imshow(wc , interpolation = 'bilinear')","execution_count":313,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"text\"] = df['text'].str.replace('[^\\w\\s]','')\ndf['text'] = df['text'].str.replace('\\d+', '')\ndf['text'] = df[\"text\"].str.lower()","execution_count":314,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer","execution_count":315,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(df.text,df.target)","execution_count":316,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tv = TfidfVectorizer()\nX = tv.fit_transform(x_train)\nY = tv.transform(x_test)\nprint(len(tv.get_feature_names()))","execution_count":317,"outputs":[{"output_type":"stream","text":"15220\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.shape)","execution_count":318,"outputs":[{"output_type":"stream","text":"(5709, 15220)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA \npca = PCA(n_components = 2) \npca.fit(X.toarray()) \nx_pca = pca.transform(X.toarray()) \nx_pca.shape   \n","execution_count":325,"outputs":[{"output_type":"execute_result","execution_count":325,"data":{"text/plain":"(5709, 2)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nimport tensorflow as tf\nmodel = Sequential()\nmodel.add(Dense(units = 100 , activation = 'relu' , input_dim = x_pca.shape[1]))\nmodel.add(Dense(units = 50 , activation = 'relu'))\nmodel.add(Dense(units = 25 , activation = 'relu'))\nmodel.add(Dense(units = 10 , activation = 'relu'))\nmodel.add(Dense(units = 1 , activation = 'sigmoid'))\nmodel.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['accuracy'])\nmodel.fit(x_pca,y_train , epochs = 10)","execution_count":327,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n5709/5709 [==============================] - 1s 204us/step - loss: 0.6325 - accuracy: 0.6586\nEpoch 2/10\n5709/5709 [==============================] - 1s 142us/step - loss: 0.6011 - accuracy: 0.6721\nEpoch 3/10\n5709/5709 [==============================] - 1s 143us/step - loss: 0.6006 - accuracy: 0.6723\nEpoch 4/10\n5709/5709 [==============================] - 1s 139us/step - loss: 0.5988 - accuracy: 0.6781\nEpoch 5/10\n5709/5709 [==============================] - 1s 158us/step - loss: 0.5946 - accuracy: 0.6754\nEpoch 6/10\n5709/5709 [==============================] - 1s 146us/step - loss: 0.5943 - accuracy: 0.6786\nEpoch 7/10\n5709/5709 [==============================] - 1s 147us/step - loss: 0.5952 - accuracy: 0.6768\nEpoch 8/10\n5709/5709 [==============================] - 1s 138us/step - loss: 0.5925 - accuracy: 0.6858\nEpoch 9/10\n5709/5709 [==============================] - 1s 139us/step - loss: 0.5957 - accuracy: 0.6791\nEpoch 10/10\n5709/5709 [==============================] - 1s 138us/step - loss: 0.5909 - accuracy: 0.6858\n","name":"stdout"},{"output_type":"execute_result","execution_count":327,"data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7fa6aef08828>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components = 2) \npca.fit(Y.toarray()) \ny_pca = pca.transform(Y.toarray()) \ny_pca.shape  ","execution_count":328,"outputs":[{"output_type":"execute_result","execution_count":328,"data":{"text/plain":"(1904, 2)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(y_pca)\n\nfor i in range(len(pred)):\n    if(pred[i] > 0.5):\n        pred[i] = 1\n    else:\n        pred[i] = 0\n        ","execution_count":329,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred","execution_count":330,"outputs":[{"output_type":"execute_result","execution_count":330,"data":{"text/plain":"array([[0.],\n       [0.],\n       [0.],\n       ...,\n       [1.],\n       [0.],\n       [0.]], dtype=float32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score \naccuracy_score(pred,y_test)","execution_count":331,"outputs":[{"output_type":"execute_result","execution_count":331,"data":{"text/plain":"0.6901260504201681"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pred.tolist()","execution_count":332,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","execution_count":333,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtc  = DecisionTreeClassifier()","execution_count":334,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtc.fit(x_pca,y_train)\n","execution_count":335,"outputs":[{"output_type":"execute_result","execution_count":335,"data":{"text/plain":"DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n                       max_depth=None, max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, presort='deprecated',\n                       random_state=None, splitter='best')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_dtc = dtc.predict(y_pca)\npred_dtc","execution_count":336,"outputs":[{"output_type":"execute_result","execution_count":336,"data":{"text/plain":"array([0, 0, 0, ..., 1, 0, 0])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score \nimport sklearn.metrics as metrics","execution_count":337,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy:\",metrics.accuracy_score(y_test, pred_dtc))","execution_count":338,"outputs":[{"output_type":"stream","text":"Accuracy: 0.6066176470588235\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.linear_model import LogisticRegression","execution_count":339,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\nlr.fit(x_pca,y_train)\n","execution_count":340,"outputs":[{"output_type":"execute_result","execution_count":340,"data":{"text/plain":"LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='auto', n_jobs=None, penalty='l2',\n                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n                   warm_start=False)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_lr = lr.predict(y_pca)\npred_lr","execution_count":341,"outputs":[{"output_type":"execute_result","execution_count":341,"data":{"text/plain":"array([0, 0, 0, ..., 1, 0, 0])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy:\",metrics.accuracy_score(y_test, pred_lr))","execution_count":342,"outputs":[{"output_type":"stream","text":"Accuracy: 0.6796218487394958\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":343,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier()","execution_count":344,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc.fit(x_pca,y_train)\n","execution_count":345,"outputs":[{"output_type":"execute_result","execution_count":345,"data":{"text/plain":"RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=None, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=100,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_rfc = rfc.predict(y_pca)\npred_rfc","execution_count":346,"outputs":[{"output_type":"execute_result","execution_count":346,"data":{"text/plain":"array([1, 0, 0, ..., 1, 0, 0])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, pred_rfc))","execution_count":347,"outputs":[{"output_type":"stream","text":"Accuracy: 0.6538865546218487\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/test.csv')","execution_count":348,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":349,"outputs":[{"output_type":"execute_result","execution_count":349,"data":{"text/plain":"   id keyword location                                               text\n0   0     NaN      NaN                 Just happened a terrible car crash\n1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just happened a terrible car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Heard about #earthquake is different cities, s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond, geese are...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = df_test.drop(['id','keyword','location'],axis=1)","execution_count":350,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\ndef rem_punct(text):\n    for punctuation in string.punctuation:\n        text = text.replace(punctuation , '')\n    return text\ndf_test['text'] = df_test['text'].apply(rem_punct)\n        ","execution_count":351,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords","execution_count":352,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk.download('stopwords')\nfrom nltk.stem.porter import PorterStemmer\nstemmer = PorterStemmer()","execution_count":353,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop = set(stopwords.words('english'))\ndef stem_text(text):\n    f_text = []\n    for i in text.split():    # split the sentenses into List With commas\n        if i.strip().lower not in stop:        #strip means you wanna strip/delete that word from list of split or delete whitespaces if no agument is passed\n            word = stemmer.stem(i.strip())\n            f_text.append(word)\n    return \" \".join(f_text)\n\ndf_test['text'] = df_test['text'].apply(stem_text)","execution_count":354,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":355,"outputs":[{"output_type":"execute_result","execution_count":355,"data":{"text/plain":"                                                text\n0                    just happen a terribl car crash\n1  heard about earthquak is differ citi stay safe...\n2  there is a forest fire at spot pond gees are f...\n3                     apocalyps light spokan wildfir\n4       typhoon soudelor kill 28 in china and taiwan","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>just happen a terribl car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>heard about earthquak is differ citi stay safe...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>there is a forest fire at spot pond gees are f...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>apocalyps light spokan wildfir</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>typhoon soudelor kill 28 in china and taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test[\"text\"] = df_test['text'].str.replace('[^\\w\\s]','')\ndf_test['text'] = df_test['text'].str.replace('\\d+', '')\ndf_test['text'] = df_test[\"text\"].str.lower()","execution_count":356,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test","execution_count":357,"outputs":[{"output_type":"execute_result","execution_count":357,"data":{"text/plain":"                                                   text\n0                       just happen a terribl car crash\n1     heard about earthquak is differ citi stay safe...\n2     there is a forest fire at spot pond gees are f...\n3                        apocalyps light spokan wildfir\n4            typhoon soudelor kill  in china and taiwan\n...                                                 ...\n3258    earthquak safeti lo angel ûò safeti fasten xrwn\n3259  storm in ri wors than last hurrican my cityamp...\n3260     green line derail in chicago httptcoutbxlcbiuy\n3261  meg issu hazard weather outlook hwo httptcoxrb...\n3262  cityofcalgari ha activ it municip emerg plan y...\n\n[3263 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>just happen a terribl car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>heard about earthquak is differ citi stay safe...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>there is a forest fire at spot pond gees are f...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>apocalyps light spokan wildfir</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>typhoon soudelor kill  in china and taiwan</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3258</th>\n      <td>earthquak safeti lo angel ûò safeti fasten xrwn</td>\n    </tr>\n    <tr>\n      <th>3259</th>\n      <td>storm in ri wors than last hurrican my cityamp...</td>\n    </tr>\n    <tr>\n      <th>3260</th>\n      <td>green line derail in chicago httptcoutbxlcbiuy</td>\n    </tr>\n    <tr>\n      <th>3261</th>\n      <td>meg issu hazard weather outlook hwo httptcoxrb...</td>\n    </tr>\n    <tr>\n      <th>3262</th>\n      <td>cityofcalgari ha activ it municip emerg plan y...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3263 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tv_test = TfidfVectorizer()\nX_test = tv_test.fit_transform(df_test.text)\n","execution_count":358,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape\npca = PCA(n_components = 2) \npca.fit(X_test.toarray()) \nxtest_pca = pca.transform(X_test.toarray()) \nxtest_pca.shape  ","execution_count":362,"outputs":[{"output_type":"execute_result","execution_count":362,"data":{"text/plain":"(3263, 2)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = lr.predict(xtest_pca)\nres","execution_count":370,"outputs":[{"output_type":"execute_result","execution_count":370,"data":{"text/plain":"array([0, 0, 1, ..., 1, 0, 0])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtest_pca.shape","execution_count":371,"outputs":[{"output_type":"execute_result","execution_count":371,"data":{"text/plain":"(3263, 2)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"res1 = res.tolist()\nres1","execution_count":378,"outputs":[{"output_type":"execute_result","execution_count":378,"data":{"text/plain":"[0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n ...]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission = pd.read_csv('/kaggle/input/sample_submission.csv')","execution_count":379,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission.head()","execution_count":380,"outputs":[{"output_type":"execute_result","execution_count":380,"data":{"text/plain":"   id  target\n0   0       0\n1   2       0\n2   3       0\n3   9       0\n4  11       0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission = Submission.drop('target',axis=1)","execution_count":381,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission","execution_count":382,"outputs":[{"output_type":"execute_result","execution_count":382,"data":{"text/plain":"         id\n0         0\n1         2\n2         3\n3         9\n4        11\n...     ...\n3258  10861\n3259  10865\n3260  10868\n3261  10874\n3262  10875\n\n[3263 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3258</th>\n      <td>10861</td>\n    </tr>\n    <tr>\n      <th>3259</th>\n      <td>10865</td>\n    </tr>\n    <tr>\n      <th>3260</th>\n      <td>10868</td>\n    </tr>\n    <tr>\n      <th>3261</th>\n      <td>10874</td>\n    </tr>\n    <tr>\n      <th>3262</th>\n      <td>10875</td>\n    </tr>\n  </tbody>\n</table>\n<p>3263 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission['target'] = res1","execution_count":384,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission.to_csv('Tweet1.csv',index=False)","execution_count":387,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}